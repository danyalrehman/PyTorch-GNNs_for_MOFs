{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "739b258c-ef37-4720-9851-22e7a5db0332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "12.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elin49/.local/lib/python3.9/site-packages/torch/cuda/__init__.py:138: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11020). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA is available\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# Print CUDA version\n",
    "print(torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942ae206-2125-48d0-89db-fc42e4082a13",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Memory: 31.67 GB\n",
      "Available Memory: 26.82 GB\n",
      "Initializing...\n",
      "cpu\n",
      "Loading structural data...\n",
      "Done loading.\n",
      "Building train, validation, and test data...\n",
      "Getting x_data, y_data...\n",
      "Splitting...\n",
      "Train y_data...\n",
      "Val y_data...\n",
      "Test y_data...\n",
      "TensorDataset...\n",
      "Done building train, validation, and test data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:27<00:00,  1.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: weighted MAE 44.1807 -> (best MAE, stored)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:35<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2: weighted MAE 42.8658 -> (best MAE, stored)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:34<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3: weighted MAE 41.6072 -> (best MAE, stored)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|███████████████████████████████████████████████▍                                   | 8/14 [00:20<00:14,  2.39s/it]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import psutil \n",
    "import argparse\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from config import *\n",
    "import dataProcess\n",
    "import CGCNN\n",
    "\n",
    "\"\"\"\n",
    "Training, testing, and validation of CGCNN model\n",
    "\"\"\"\n",
    "\n",
    "# Get system memory information\n",
    "mem = psutil.virtual_memory()\n",
    "print(f\"Total Memory: {mem.total / (1024 ** 3):.2f} GB\", flush=True)\n",
    "print(f\"Available Memory: {mem.available / (1024 ** 3):.2f} GB\", flush=True)\n",
    "\n",
    "class TrainCGCNN():\n",
    "    \"\"\"\n",
    "    Train crystal graph convolutional neural network (CGCNN)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        print(\"Initializing...\", flush=True)\n",
    "        \n",
    "        # Initialize general parameters\n",
    "        job_path = os.path.join(jobPath, jobName)         # log directory\n",
    "        if not os.path.exists(jobPath):\n",
    "            os.makedirs(jobPath)\n",
    "\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")          # device\n",
    "        print(self.device, flush=True)\n",
    "        \n",
    "        self.dtype = torch.set_default_dtype(torch.float64 if fp64 else torch.float32)        # dtype\n",
    "\n",
    "        # Initialize dataset\n",
    "        L_y_isotherm = 3                     # number of parameters to represent isotherm curve\n",
    "        L_y_enthalpy = 3                     # number of parameters to represent enthalpy curve (average)\n",
    "        L_y_enthalpy_LB = L_y_enthalpy                     # number of parameters to represent enthalpy curve (lower bound)\n",
    "        L_y_enthalpy_UB = L_y_enthalpy                     # number of parameters to represent enthalpy curve (upper bound)\n",
    "        \n",
    "        self.L_y_isotherm = L_y_isotherm\n",
    "        self.L_y_enthalpy = L_y_enthalpy\n",
    "        self.L_y_enthalpy_LB = L_y_enthalpy_LB\n",
    "        self.L_y_enthalpy_UB = L_y_enthalpy_UB\n",
    "        \n",
    "        if train:\n",
    "            if run_dataProcess:\n",
    "                _, structureInputs = dataProcess.structure_inputs(dataDir=dataPath)\n",
    "            else:\n",
    "                print(\"Loading structural data...\", flush=True)\n",
    "                structureInputs = torch.load(dataPath+\"X_dataset.pth\")\n",
    "                print(\"Done loading.\", flush=True)\n",
    "                \n",
    "            print(\"Building train, validation, and test data...\", flush=True)\n",
    "            nodeFeat, bondFeat, connectivityFeat = structureInputs[\"nodeFeat\"], structureInputs[\"bondFeat\"], structureInputs[\"connectivityFeat\"]\n",
    "            bondFeat = bondFeat[:, :nodeFeat.size(1), :nodeFeat.size(1)]\n",
    "            connectivityFeat = connectivityFeat[:, :nodeFeat.size(1), :nodeFeat.size(1)]\n",
    "\n",
    "            print(\"Getting x_data, y_data...\", flush=True)\n",
    "            x_data = torch.cat((nodeFeat, bondFeat, connectivityFeat), dim=2).double()\n",
    "            y_data = dataProcess.structure_outputs(dataDir=dataPath)\n",
    "\n",
    "            print(\"Splitting...\", flush=True)\n",
    "            x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.2, random_state=42)\n",
    "            x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "            print(\"Train y_data...\", flush=True)\n",
    "            y_train_isotherm = y_train[:, 0:self.L_y_isotherm].double()\n",
    "            y_train_enthalpy = y_train[:, self.L_y_isotherm:self.L_y_isotherm+self.L_y_enthalpy].double()    \n",
    "            y_train_enthalpy_LB = y_train[:, self.L_y_isotherm+self.L_y_enthalpy:self.L_y_isotherm+self.L_y_enthalpy+self.L_y_enthalpy_LB].double()     \n",
    "            y_train_enthalpy_UB = y_train[:, self.L_y_isotherm+self.L_y_enthalpy+self.L_y_enthalpy_LB:self.L_y_isotherm+self.L_y_enthalpy+self.L_y_enthalpy_LB+self.L_y_enthalpy_UB].double()  \n",
    "            \n",
    "            print(\"Val y_data...\", flush=True)\n",
    "            y_val_isotherm = y_val[:, 0:self.L_y_isotherm].double()  \n",
    "            y_val_enthalpy = y_val[:, self.L_y_isotherm:self.L_y_isotherm+self.L_y_enthalpy].double()    \n",
    "            y_val_enthalpy_LB = y_val[:, self.L_y_isotherm+self.L_y_enthalpy:self.L_y_isotherm+self.L_y_enthalpy+self.L_y_enthalpy_LB].double()     \n",
    "            y_val_enthalpy_UB = y_val[:, self.L_y_isotherm+self.L_y_enthalpy+self.L_y_enthalpy_LB:self.L_y_isotherm+self.L_y_enthalpy+self.L_y_enthalpy_LB+self.L_y_enthalpy_UB].double()\n",
    "            \n",
    "            print(\"Test y_data...\", flush=True)\n",
    "            y_test_isotherm = y_test[:, 0:self.L_y_isotherm].double()  \n",
    "            y_test_enthalpy = y_test[:, self.L_y_isotherm:self.L_y_isotherm+self.L_y_enthalpy].double()    \n",
    "            y_test_enthalpy_LB = y_test[:, self.L_y_isotherm+self.L_y_enthalpy:self.L_y_isotherm+self.L_y_enthalpy+self.L_y_enthalpy_LB].double()     \n",
    "            y_test_enthalpy_UB = y_test[:, self.L_y_isotherm+self.L_y_enthalpy+self.L_y_enthalpy_LB:self.L_y_isotherm+self.L_y_enthalpy+self.L_y_enthalpy_LB+self.L_y_enthalpy_UB].double()  \n",
    "            \n",
    "            print(\"TensorDataset...\", flush=True)\n",
    "            train_dataset = TensorDataset(x_train, y_train_isotherm, y_train_enthalpy, y_train_enthalpy_LB, y_train_enthalpy_UB)\n",
    "            val_dataset = TensorDataset(x_val, y_val_isotherm, y_val_enthalpy, y_val_enthalpy_LB, y_val_enthalpy_UB)\n",
    "            self.train_DataLoader = DataLoader(train_dataset, batch_size=train_batchSize, shuffle=True, pin_memory=True)\n",
    "            self.val_DataLoader = DataLoader(val_dataset, batch_size=val_batchSize, shuffle=True, pin_memory=True)\n",
    "\n",
    "        if test:\n",
    "            test_dataset = TensorDataset(x_test, y_test_isotherm, y_test_enthalpy, y_test_enthalpy_LB, y_test_enthalpy_UB)\n",
    "            self.test_DataLoader = DataLoader(test_dataset, batch_size=test_batchSize, shuffle=True, pin_memory=True)\n",
    "            \n",
    "        print(\"Done building train, validation, and test data.\", flush=True)\n",
    "\n",
    "        # Initialize model\n",
    "        structureParams = {\n",
    "            \"dim_in\": nodeFeat.size(2) + bondFeat.size(2),    # nodeFeat.size(1) + bondFeat.size(1) number of features you input (node + bond features + TEXTURAL FEATURES) -STILL NEED TO ADD TEXTURAL FEATURES!!!!!!!!!\n",
    "            \n",
    "            \"n_convLayer\": 3,\n",
    "            \"dim_out\": [128, 64, 32],                  \n",
    "            \n",
    "            \"n_hidLayer_pool\": 2,\n",
    "            \"dim_hidFeat\": [32, 16],\n",
    "            \n",
    "            \"dim_fc_out\": [L_y_isotherm, L_y_enthalpy, L_y_enthalpy_LB, L_y_enthalpy_UB]\n",
    "        }\n",
    "\n",
    "        self.model = CGCNN.CGCNNModel(structureParams)\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "        self.N = nodeFeat.size(1)            # max number of nodes across all crystal structures\n",
    "\n",
    "        # Initialize optimizer and scheduler\n",
    "        if optimizer in [\"sgd\", \"SGD\"]:\n",
    "            self.optimizer = torch.optim.SGD(self.model.parameters(), lr=lr)\n",
    "        elif optimizer in [\"Adam\", \"adam\"]:\n",
    "            self.optimizer = torch.optim.Adam(self.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        elif optimizer in ['Adamax', 'adamax']:\n",
    "            self.optimizer = torch.optim.Adamax(self.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "        self.scheduler = torch.optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=scheduler_gamma)\n",
    "\n",
    "        # Load checkpoint\n",
    "        self.logPath = os.path.join(jobPath, \"train_log.txt\")\n",
    "        self.start_epoch = 0\n",
    "        if not disable_checkpt:\n",
    "            self.statePath = os.path.join(jobPath, \"state_dicts\")\n",
    "            if os.path.exists(self.statePath):\n",
    "                shutil.rmtree(self.statePath)\n",
    "            if os.path.exists(self.statePath) and len(os.listdir(self.statePath)) > 0:\n",
    "                for i in range(num_epoch, 0, -1):\n",
    "                    fileName = os.path.join(self.statePath, f\"epoch_{i}_sd.pt\")\n",
    "                    if os.path.isfile(fileName):\n",
    "                        checkpoint = torch.load(fileName)\n",
    "                        self.model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "                        self.optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "                        self.scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
    "                        self.start_epoch = checkpoint[\"epoch\"]\n",
    "                        self.model.eval()\n",
    "                        break\n",
    "            elif not os.path.exists(self.statePath):\n",
    "                os.mkdir(self.statePath)\n",
    "\n",
    "    def calcLoss(self, y_pred_isotherm, y_pred_enthalpy, y_pred_enthalpy_LB, y_pred_enthalpy_UB, y_target_isotherm, y_target_enthalpy, y_target_enthalpy_LB, y_target_enthalpy_UB):\n",
    "        # convert all to double\n",
    "        y_pred_isotherm = y_pred_isotherm.double()\n",
    "        y_pred_enthalpy = y_pred_enthalpy.double()\n",
    "        y_pred_enthalpy_LB = y_pred_enthalpy_LB.double()\n",
    "        y_pred_enthalpy_UB = y_pred_enthalpy_UB.double()\n",
    "        \n",
    "        # mse\n",
    "        mse_isotherm = nn.MSELoss()(y_pred_isotherm, y_target_isotherm)     \n",
    "        mse_enthalpy = nn.MSELoss()(y_pred_enthalpy, y_target_enthalpy)    \n",
    "        mse_enthalpy_LB = nn.MSELoss()(y_pred_enthalpy_LB, y_target_enthalpy_LB)     \n",
    "        mse_enthalpy_UB = nn.MSELoss()(y_pred_enthalpy_UB, y_target_enthalpy_UB)  \n",
    "        \n",
    "        # mae\n",
    "        mae_isotherm = nn.L1Loss()(y_pred_isotherm, y_target_isotherm)     \n",
    "        mae_enthalpy = nn.L1Loss()(y_pred_enthalpy, y_target_enthalpy) \n",
    "        mae_enthalpy_LB = nn.L1Loss()(y_pred_enthalpy_LB, y_target_enthalpy_LB)   \n",
    "        mae_enthalpy_UB = nn.L1Loss()(y_pred_enthalpy_UB, y_target_enthalpy_UB)\n",
    "        \n",
    "        # NOT SURE???\n",
    "        mse = mse_isotherm + mse_enthalpy + mse_enthalpy_LB + mse_enthalpy_UB\n",
    "        mae = mae_isotherm + mae_enthalpy + mae_enthalpy_LB + mae_enthalpy_UB\n",
    "        \n",
    "        \n",
    "        # print(mse_isotherm, mse_enthalpy, mse_enthalpy_LB, mse_enthalpy_UB)\n",
    "        # print(mae_isotherm, mae_enthalpy, mae_enthalpy_LB, mae_enthalpy_UB)\n",
    "        \n",
    "        return mse, mae\n",
    "\n",
    "    def train(self):\n",
    "        N = self.N  # max number of nodes across all crystal structures\n",
    "        best_mae = 1e10\n",
    "        best_mae_epoch = 0\n",
    "        for epoch in range(self.start_epoch, num_epoch):\n",
    "            # Train\n",
    "            train_mse = []\n",
    "            train_mae = []\n",
    "\n",
    "            self.model.train()            \n",
    "            for batch, (x_data_conn, y_data_isotherm, y_data_enthalpy, y_data_enthalpy_LB, y_data_enthalpy_UB) in tqdm(enumerate(self.train_DataLoader), total=len(self.train_DataLoader)):                \n",
    "                # Separate x_data (node features) from connectivity matrix\n",
    "                batch_size_train = x_data_conn.size(0)  # batch size (in training loop - number of crystal structures in the batch)\n",
    "                \n",
    "                x_node_train = x_data_conn[:, :, 0:-(2 * N)]\n",
    "                x_bond_train = x_data_conn[:, :, -(2 * N):-N]\n",
    "                x_connectivity_train = x_data_conn[:, :, -N:]\n",
    "\n",
    "                x_data_train = [x_node_train, x_bond_train, x_connectivity_train]\n",
    "\n",
    "                # all crystal structures are padded so max. num. of nodes are the same\n",
    "                batchAssign_train = torch.tensor([b for b in range(batch_size_train) for n in range(N)])\n",
    "\n",
    "                y_pred_isotherm, y_pred_enthalpy, y_pred_enthalpy_LB, y_pred_enthalpy_UB = self.model(x_data_train, batchAssign_train)\n",
    "                mse, mae = self.calcLoss(y_pred_isotherm, y_pred_enthalpy, y_pred_enthalpy_LB, y_pred_enthalpy_UB, y_data_isotherm, y_data_enthalpy, y_data_enthalpy_LB, y_data_enthalpy_UB)\n",
    "                \n",
    "                self.optimizer.zero_grad()\n",
    "                mse.backward()\n",
    "                self.optimizer.step()\n",
    "                train_mse.append(mse.item())\n",
    "                train_mae.append(mae.item())\n",
    "            self.scheduler.step()\n",
    "\n",
    "            # Validation\n",
    "            val_mse = []\n",
    "            val_mae = []\n",
    "            self.model.eval()\n",
    "            for batch, (x_data_conn, y_data_isotherm, y_data_enthalpy, y_data_enthalpy_LB, y_data_enthalpy_UB) in enumerate(self.val_DataLoader):\n",
    "                batch_size_val = x_data_conn.size(0)  # batch size (in training loop - number of crystal structures in the batch)\n",
    "\n",
    "                x_node_val = x_data_conn[:, :, 0:-(2 * N)]\n",
    "                x_bond_val = x_data_conn[:, :, -(2 * N):-N]\n",
    "                x_connectivity_val = x_data_conn[:, :, -N:]\n",
    "\n",
    "                x_data_val = [x_node_val, x_bond_val, x_connectivity_val]\n",
    "\n",
    "                # all crystal structures are padded so max. num. of nodes are the same\n",
    "                batchAssign_val = torch.tensor([b for b in range(batch_size_val) for n in range(N)])\n",
    "\n",
    "                y_pred_isotherm, y_pred_enthalpy, y_pred_enthalpy_LB, y_pred_enthalpy_UB = self.model(x_data_val, batchAssign_val)\n",
    "                mse, mae = self.calcLoss(y_pred_isotherm, y_pred_enthalpy, y_pred_enthalpy_LB, y_pred_enthalpy_UB, y_data_isotherm, y_data_enthalpy, y_data_enthalpy_LB, y_data_enthalpy_UB)\n",
    "                val_mse.append(mse.item())\n",
    "                val_mae.append(mae.item())\n",
    "\n",
    "            if np.mean(val_mae) < best_mae:\n",
    "                best_mae = np.mean(val_mae)\n",
    "                best_mae_epoch = epoch\n",
    "                print(f'epoch {epoch + 1}: weighted MAE {np.mean(val_mae):.4f} -> (best MAE, stored)', flush=True)\n",
    "                print(f'epoch {epoch + 1}: weighted MAE {np.mean(val_mae):.4f} -> (best MAE, stored)', file=open(self.logPath, 'a'))                \n",
    "            else:\n",
    "                print(f'epoch {epoch + 1}: weighted MAE {np.mean(val_mae):.4f}', flush=True)\n",
    "\n",
    "            # Save checkpoint every epoch\n",
    "            if not disable_checkpt:\n",
    "                statedict_filename = os.path.join(self.statedict_path, f\"epoch_{epoch + 1}_sd.pt\")\n",
    "                torch.save({\n",
    "                    \"epoch\": epoch + 1,\n",
    "                    \"model_state_dict\": self.model.state_dict(),\n",
    "                    \"optimizer_state_dict\": self.optimizer.state_dict(),\n",
    "                    \"scheduler_state_dict\": self.scheduler.state_dict()\n",
    "                }, statedict_filename)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epoch}, Average mse: {np.mean(val_mse):.4f}\", flush=True)\n",
    "\n",
    "        return best_mae_epoch + 1\n",
    "\n",
    "\n",
    "    def test(self, best_epoch=0):\n",
    "        N = self.N  # max number of nodes across all crystal structures\n",
    "        if not best_epoch:\n",
    "            best_epoch = num_epoch\n",
    "        # fileName = os.path.join(self.statePath, f\"epoch_{best_epoch}_sd.pt\")\n",
    "        # checkpoint = torch.load(fileName)\n",
    "        # self.model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        # self.optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        # self.scheduler.load_state_dict(checkpoint[\"scheduler_state_dict\"])\n",
    "        # self.start_epoch = checkpoint[\"epoch\"]\n",
    "\n",
    "        # Testing / Validation\n",
    "        val_mse = []\n",
    "        val_mae = []\n",
    "        self.model.eval()\n",
    "        for batch, (x_data_conn, y_data_isotherm, y_data_enthalpy, y_data_enthalpy_LB, y_data_enthalpy_UB) in enumerate(self.test_DataLoader):\n",
    "            batch_size_val = x_data_conn.size(0)  # batch size (in training loop - number of crystal structures in the batch)\n",
    "\n",
    "            x_node_val = x_data_conn[:, :, 0:-(2 * N)]\n",
    "            x_bond_val = x_data_conn[:, :, -(2 * N):-N]\n",
    "            x_connectivity_val = x_data_conn[:, :, -N:]\n",
    "\n",
    "            x_data_val = [x_node_val, x_bond_val, x_connectivity_val]\n",
    "\n",
    "            # all crystal structures are padded so max. num. of nodes are the same - tells us which nodes correspond to which crystal in the batch\n",
    "            batchAssign_val = torch.tensor([b for b in range(batch_size_val) for n in range(N)])        # needs to be repeated batch_size times (0,0,0, ..., batch_size-1, batch_size-1, batch_size-1)\n",
    "\n",
    "            y_pred_isotherm, y_pred_enthalpy, y_pred_enthalpy_LB, y_pred_enthalpy_UB = self.model(x_data_val, batchAssign_val)        \n",
    "            mse, mae = self.calcLoss(y_pred_isotherm, y_pred_enthalpy, y_pred_enthalpy_LB, y_pred_enthalpy_UB, y_data_isotherm, y_data_enthalpy, y_data_enthalpy_LB, y_data_enthalpy_UB)\n",
    "            val_mse.append(mse.item())\n",
    "            val_mae.append(mae.item())\n",
    "\n",
    "            print(f\"Average mse {np.mean(val_mse):.4f}, Average MAE: {np.mean(val_mae):.4f}\", flush=True)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    trainer = TrainCGCNN()\n",
    "    best_epoch = trainer.train()\n",
    "    trainer.test(best_epoch=best_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef4c9b9-54f5-401c-a458-45a5d2dbd1f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
